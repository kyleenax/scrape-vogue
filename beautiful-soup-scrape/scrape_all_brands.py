from playwright.sync_api import sync_playwright
import pandas as pd
import time

# ‚úÖ Load shows from CSV
shows_df = pd.read_csv("v1.csv")

# ‚úÖ Dictionary to store season-wise brand names
season_brands = {}

def scrape_brands():
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)  # Set False for debugging
        page = browser.new_page()

        for _, row in shows_df.iterrows():
            season = row["season"]
            show_url = row["url"]

            print(f"üîç Scraping brands for {season} ({show_url})")
            try:
                page.goto(show_url, timeout=1200000)  # 60 seconds timeout
                time.sleep(2)  # Allow extra time to load content

                print("querying in progress")

                # ‚úÖ Find brand links using `#main-content .navigation__link`
                brand_elements = page.query_selector_all("#main-content .navigation__link")

                brands = [brand.inner_text().strip() for brand in brand_elements if brand.inner_text().strip()]

                # ‚úÖ Store brand names as a comma-separated string
                season_brands[season] = ", ".join(brands)
                print(f"üìå Brands found for {season}: {season_brands[season]}")

            except Exception as e:
                print(f"‚ùå Error scraping {season}: {e}")
                season_brands[season] = "Error"

        browser.close()

    # ‚úÖ Merge scraped brand names into the original CSV
    shows_df["list-of-brands"] = shows_df["season"].map(season_brands)
    shows_df.to_csv("v1.csv", index=False)
    print("‚úÖ Scraping completed! Data updated in `v1.csv`")

# ‚úÖ Run the scraper
scrape_brands()
